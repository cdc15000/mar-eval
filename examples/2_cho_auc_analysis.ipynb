{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68623da1",
   "metadata": {},
   "source": [
    "# Notebook 2: CHO Analysis and ROC/AUC Computation\n",
    "\n",
    "This notebook performs CHO scoring and ROC analysis using **scikit-learn** utilities and the **mar-eval** API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14acf820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from mareval import cho_decision_values\n",
    "\n",
    "rng = np.random.default_rng(7)\n",
    "N = 1000\n",
    "C = 5  # channels\n",
    "# Generate multichannel synthetic features for non-MAR and MAR\n",
    "x0 = rng.normal(0, 1, size=(N, C))\n",
    "x1 = rng.normal(0, 1, size=(N, C)) + np.r_[0.25, 0.2, 0.15, 0.1, 0.05]\n",
    "labels = np.r_[np.zeros(N), np.ones(N)]\n",
    "X = np.vstack([x0, x1])\n",
    "w = x1.mean(0) - x0.mean(0)\n",
    "scores = cho_decision_values(X, w)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(labels, scores)\n",
    "auc_val = auc(fpr, tpr)\n",
    "print('AUC:', round(auc_val, 3))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC (AUC={auc_val:.3f})')\n",
    "plt.plot([0,1], [0,1], '--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('CHO ROC Curve (Synthetic)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094261d1",
   "metadata": {},
   "source": [
    "**Annex GG terminology mapping**\n",
    "\n",
    "- *Channels* correspond to the channel template matrix application.\n",
    "- *CHO* provides a task-based observer consistent with Annex GG.\n",
    "- *ROC/AUC* uses standard definitions via scikit-learn.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
