# mar-eval ğŸ©»  
**Objective Evaluation Toolkit for Metal Artifact Reduction (MAR) Algorithms in CT Imaging**

[![mar-eval CI](https://github.com/cdc15000/mar-eval/actions/workflows/tests.yml/badge.svg)](https://github.com/cdc15000/mar-eval/actions)

`mar-eval` is an open-source Python toolkit that implements the analysis framework described in **Annex GG** of the proposed IEC 60601-2-44 Ed. 4.  
It enables objective evaluation of **Metal Artifact Reduction (MAR)** algorithms in CT imaging using the **Channelized Hotelling Observer (CHO)**, **AUC-based detectability metrics**, and **bias assessment** between MAR and non-MAR reconstructions.

---

## ğŸ” Purpose

`mar-eval` supports regulatory, clinical, and technical validation of MAR performance by providing reproducible, quantitative methods for:
- Computing **Area Under the ROC Curve (AUC)** using CHO-derived decision variables  
- Performing **paired statistical comparison** of MAR vs. non-MAR detectability  
- Estimating **confidence intervals** and **Î”AUC bias**  
- Enabling interoperability across CT simulators, physical phantoms, and regulatory test environments

---

## ğŸ“˜ Example Notebook

A runnable Jupyter Notebook, [`examples/mar_eval_demo.ipynb`](examples/mar_eval_demo.ipynb), walks through the full workflow described in **Annex GG**:

1. **GG.2 â€“ Model Observer Task**  
   Simulates lesion-present and lesion-absent image sets using Gaussian statistics.  
2. **GG.3 â€“ Data Evaluation**  
   Computes CHO decision values, ROC curves, and AUC estimates.  
3. **GG.4 â€“ Statistical Comparison**  
   Uses a one-tailed paired t-test to detect significant improvements in detectability.  
4. **GG.5 â€“ Bias Assessment**  
   Quantifies Î”AUC and confidence intervals to evaluate MAR-related bias.

---

## âš™ï¸ Installation

Install directly from [PyPI](https://pypi.org/project/mar-eval/):

```bash
pip install mar-eval
```

Or, for the latest development version:

```bash
pip install git+https://github.com/cdc15000/mar-eval.git
```

---

## ğŸ§ª Running the Example

```bash
# Clone the repository
git clone https://github.com/cdc15000/mar-eval.git
cd mar-eval

# Install dependencies
pip install -r requirements.txt

# Launch JupyterLab
jupyter lab

# Open and run the example notebook
examples/mar_eval_demo.ipynb
```

---

## ğŸ“Š Output Example

The notebook produces AUC estimates and statistical comparison similar to:

```
AUC (no MAR): 0.484  CI: (0.423, 0.538)
AUC (with MAR): 0.504  CI: (0.445, 0.558)
Î”AUC = 0.020, p = 0.0005
```

---

## ğŸ§© Package Structure

```
mareval/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ cho.py           # CHO computation routines
â”œâ”€â”€ stats.py         # AUC, bias, and statistical testing
â”œâ”€â”€ utils.py         # Helper utilities
examples/
â””â”€â”€ mar_eval_demo.ipynb
tests/
â””â”€â”€ test_mareval_basic.py
```

---

## ğŸ§¾ Citation

If you use `mar-eval` in your research, please cite:

> C.D. Cocchiaraley, *Annex GG â€” Objective evaluation of Metal Artifact Reduction algorithms in CT imaging*,  
> Proposed addition to IEC 60601-2-44 Ed. 4 (2025).

---

## ğŸªª License

MIT License â€” see [LICENSE](LICENSE) for details.

---

## ğŸ¤ Contributing

Contributions, issue reports, and pull requests are welcome.  
Please open an [issue](https://github.com/cdc15000/mar-eval/issues) or submit a PR with your proposed improvements.

---

Â© 2025 Christopher D. Cocchiaraley. All rights reserved.
